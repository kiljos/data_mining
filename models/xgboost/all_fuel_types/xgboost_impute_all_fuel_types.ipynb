{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c700272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../..\"))\n",
    "\n",
    "\n",
    "from Preprocessing.preprocessing_pipeline_impute import preprocessing_pipeline\n",
    "from Preprocessing.imputation import get_imputation_maps, apply_imputation,ContextImputer\n",
    "from Preprocessing.preprocessing_pipeline_segment import preprocessing_pipeline_segment\n",
    "from Preprocessing.split_new import split_data\n",
    "from utils.eval_call import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb67ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "XGBoost Performance Metrics:\n",
      "MAE: 4198.23\n",
      "MSE: 670613376.00\n",
      "RMSE: 25896.20\n",
      "RÂ²: 0.68\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1) Daten laden / splitten\n",
    "    X_train, X_test, y_train, y_test, cat_feats, num_feats = split_data('../../../data.csv')\n",
    "    \n",
    "    # 2) Transformer\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, num_feats),\n",
    "        ('cat', categorical_transformer, cat_feats)\n",
    "    ])\n",
    "\n",
    "    # 3) XGBoost-Pipeline\n",
    "    xgb_pipeline = Pipeline([\n",
    "        ('imp_fc', ContextImputer('fuel_consumption_l_100km')),\n",
    "        ('imp_ps', ContextImputer('power_ps')),\n",
    "        ('imp_er', ContextImputer('electric_range')),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', xgb.XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=7,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"Training XGBoost model...\")\n",
    "\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = xgb_pipeline.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred, \"XGBoost\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
