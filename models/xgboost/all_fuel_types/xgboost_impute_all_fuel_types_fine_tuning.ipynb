{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c700272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../../..\"))\n",
    "\n",
    "\n",
    "from Preprocessing.preprocessing_pipeline_impute import preprocessing_pipeline\n",
    "from Preprocessing.imputation import get_imputation_maps, apply_imputation,ContextImputer\n",
    "from Preprocessing.preprocessing_pipeline_segment import preprocessing_pipeline_segment\n",
    "from Preprocessing.split_new import split_data\n",
    "from utils.eval_call import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb67ca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "                              feature      gain\n",
      "0              cat__brand_lamborghini  0.069793\n",
      "1                  cat__brand_ferrari  0.059224\n",
      "2             cat__fuel_type_Electric  0.051922\n",
      "3                       num__power_ps  0.044058\n",
      "4              cat__model_Lamborghini  0.035620\n",
      "5    cat__model_Lamborghini Aventador  0.029109\n",
      "6              cat__model_Porsche 918  0.029104\n",
      "7                  cat__brand_bentley  0.027363\n",
      "8                    cat__brand_dodge  0.026340\n",
      "9               cat__fuel_type_Hybrid  0.022349\n",
      "10            cat__brand_aston-martin  0.018603\n",
      "11                 cat__brand_porsche  0.017868\n",
      "12    cat__model_Aston Martin Vantage  0.017273\n",
      "13   cat__transmission_type_Automatic  0.017071\n",
      "14             cat__model_Porsche 991  0.016391\n",
      "15                 cat__fuel_type_CNG  0.014157\n",
      "16      cat__model_Porsche Carrera GT  0.013637\n",
      "17                    cat__brand_jeep  0.013022\n",
      "18       cat__model_Ferrari Portofino  0.011738\n",
      "19                 cat__model_BMW 550  0.011181\n",
      "20    cat__model_Lamborghini Gallardo  0.010990\n",
      "21            cat__model_Ferrari Roma  0.010919\n",
      "22                  cat__model_BMW Z8  0.009096\n",
      "23             cat__model_Ferrari 599  0.008491\n",
      "24             cat__model_Porsche 992  0.008202\n",
      "25  cat__model_Mercedes-Benz G 63 AMG  0.008154\n",
      "26       cat__model_Mercedes-Benz SLR  0.008072\n",
      "27            cat__model_Ford Mustang  0.008057\n",
      "28                     cat__brand_bmw  0.007707\n",
      "29        cat__model_Dodge Challenger  0.007629\n",
      "1393\n",
      "XGBoost Performance Metrics:\n",
      "MAE: 4198.23\n",
      "MSE: 670613376.00\n",
      "RMSE: 25896.20\n",
      "RÂ²: 0.68\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1) Daten laden / splitten\n",
    "    X_train, X_test, y_train, y_test, cat_feats, num_feats = split_data('../../../data.csv')\n",
    "    \n",
    "    # 2) Transformer\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, num_feats),\n",
    "        ('cat', categorical_transformer, cat_feats)\n",
    "    ])\n",
    "\n",
    "    # 3) XGBoost-Pipeline\n",
    "    xgb_pipeline = Pipeline([\n",
    "        ('imp_fc', ContextImputer('fuel_consumption_l_100km')),\n",
    "        ('imp_ps', ContextImputer('power_ps')),\n",
    "        ('imp_er', ContextImputer('electric_range')),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', xgb.XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=7,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"Training XGBoost model...\")\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # --- nach dem Fit ---\n",
    "    xgb_model      = xgb_pipeline.named_steps['model']          # XGBRegressor-Objekt\n",
    "\n",
    "\n",
    "    feature_names  = (\n",
    "        xgb_pipeline.named_steps['preprocessor']\n",
    "        .get_feature_names_out()         \n",
    "    )\n",
    "\n",
    "    # Gain-Importance direkt aus XGBoost\n",
    "    importances = xgb_model.feature_importances_   # numpy-Array\n",
    "\n",
    "    # ðŸ‘‰ DataFrame bauen & sortieren\n",
    "    fi = (pd.DataFrame({'feature': feature_names,\n",
    "                        'gain'   : importances})\n",
    "            .sort_values('gain', ascending=False)\n",
    "            .reset_index(drop=True))\n",
    "    print(fi.head(30))\n",
    "    (print(len(fi)))\n",
    "    y_pred = xgb_pipeline.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred, \"XGBoost\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7aecf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost model...\n",
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] END model__colsample_bytree=0.6399899663272012, model__gamma=2.2962444598293357, model__learning_rate=0.06005629167085327, model__max_depth=7, model__min_child_weight=6, model__n_estimators=608, model__subsample=0.9879639408647978; total time=  13.5s\n",
      "[CV] END model__colsample_bytree=0.6399899663272012, model__gamma=2.2962444598293357, model__learning_rate=0.06005629167085327, model__max_depth=7, model__min_child_weight=6, model__n_estimators=608, model__subsample=0.9879639408647978; total time=  13.5s\n",
      "[CV] END model__colsample_bytree=0.6399899663272012, model__gamma=2.2962444598293357, model__learning_rate=0.06005629167085327, model__max_depth=7, model__min_child_weight=6, model__n_estimators=608, model__subsample=0.9879639408647978; total time=  13.6s\n",
      "[CV] END model__colsample_bytree=0.749816047538945, model__gamma=4.75357153204958, model__learning_rate=0.11979909127171076, model__max_depth=9, model__min_child_weight=5, model__n_estimators=914, model__subsample=0.7783331011414365; total time=  17.5s\n",
      "[CV] END model__colsample_bytree=0.749816047538945, model__gamma=4.75357153204958, model__learning_rate=0.11979909127171076, model__max_depth=9, model__min_child_weight=5, model__n_estimators=914, model__subsample=0.7783331011414365; total time=  17.8s\n",
      "[CV] END model__colsample_bytree=0.749816047538945, model__gamma=4.75357153204958, model__learning_rate=0.11979909127171076, model__max_depth=9, model__min_child_weight=5, model__n_estimators=914, model__subsample=0.7783331011414365; total time=  18.3s\n",
      "[CV] END model__colsample_bytree=0.9329770563201687, model__gamma=1.0616955533913808, model__learning_rate=0.03727374508106509, model__max_depth=9, model__min_child_weight=1, model__n_estimators=759, model__subsample=0.8446612641953124; total time=  19.2s\n",
      "[CV] END model__colsample_bytree=0.9329770563201687, model__gamma=1.0616955533913808, model__learning_rate=0.03727374508106509, model__max_depth=9, model__min_child_weight=1, model__n_estimators=759, model__subsample=0.8446612641953124; total time=  19.5s\n",
      "[CV] END model__colsample_bytree=0.6028265220878869, model__gamma=0.11531212520707879, model__learning_rate=0.08871619903875837, model__max_depth=6, model__min_child_weight=3, model__n_estimators=866, model__subsample=0.9932923543227152; total time=  15.0s\n",
      "[CV] END model__colsample_bytree=0.6028265220878869, model__gamma=0.11531212520707879, model__learning_rate=0.08871619903875837, model__max_depth=6, model__min_child_weight=3, model__n_estimators=866, model__subsample=0.9932923543227152; total time=  14.9s\n",
      "[CV] END model__colsample_bytree=0.786705157299192, model__gamma=4.299702033681603, model__learning_rate=0.11204613078816694, model__max_depth=5, model__min_child_weight=7, model__n_estimators=573, model__subsample=0.9795542149013333; total time=  12.7s\n",
      "[CV] END model__colsample_bytree=0.786705157299192, model__gamma=4.299702033681603, model__learning_rate=0.11204613078816694, model__max_depth=5, model__min_child_weight=7, model__n_estimators=573, model__subsample=0.9795542149013333; total time=  12.7s\n",
      "[CV] END model__colsample_bytree=0.786705157299192, model__gamma=4.299702033681603, model__learning_rate=0.11204613078816694, model__max_depth=5, model__min_child_weight=7, model__n_estimators=573, model__subsample=0.9795542149013333; total time=  12.6s\n",
      "[CV] END model__colsample_bytree=0.6028265220878869, model__gamma=0.11531212520707879, model__learning_rate=0.08871619903875837, model__max_depth=6, model__min_child_weight=3, model__n_estimators=866, model__subsample=0.9932923543227152; total time=  15.4s\n",
      "[CV] END model__colsample_bytree=0.9329770563201687, model__gamma=1.0616955533913808, model__learning_rate=0.03727374508106509, model__max_depth=9, model__min_child_weight=1, model__n_estimators=759, model__subsample=0.8446612641953124; total time=  20.2s\n",
      "[CV] END model__colsample_bytree=0.9862528132298237, model__gamma=4.041986740582305, model__learning_rate=0.0556920653760056, model__max_depth=9, model__min_child_weight=2, model__n_estimators=639, model__subsample=0.6964101864104046; total time=  16.8s\n",
      "[CV] END model__colsample_bytree=0.9862528132298237, model__gamma=4.041986740582305, model__learning_rate=0.0556920653760056, model__max_depth=9, model__min_child_weight=2, model__n_estimators=639, model__subsample=0.6964101864104046; total time=  17.4s\n",
      "[CV] END model__colsample_bytree=0.9862528132298237, model__gamma=4.041986740582305, model__learning_rate=0.0556920653760056, model__max_depth=9, model__min_child_weight=2, model__n_estimators=639, model__subsample=0.6964101864104046; total time=  18.4s\n",
      "[CV] END model__colsample_bytree=0.8733054075301833, model__gamma=3.0499832889131047, model__learning_rate=0.13497923676042464, model__max_depth=7, model__min_child_weight=1, model__n_estimators=861, model__subsample=0.8650089137415928; total time=  17.8s\n",
      "[CV] END model__colsample_bytree=0.8733054075301833, model__gamma=3.0499832889131047, model__learning_rate=0.13497923676042464, model__max_depth=7, model__min_child_weight=1, model__n_estimators=861, model__subsample=0.8650089137415928; total time=  17.6s\n",
      "[CV] END model__colsample_bytree=0.8733054075301833, model__gamma=3.0499832889131047, model__learning_rate=0.13497923676042464, model__max_depth=7, model__min_child_weight=1, model__n_estimators=861, model__subsample=0.8650089137415928; total time=  17.8s\n",
      "[CV] END model__colsample_bytree=0.7246844304357644, model__gamma=2.600340105889054, model__learning_rate=0.09200654190149193, model__max_depth=9, model__min_child_weight=2, model__n_estimators=855, model__subsample=0.9757995766256756; total time=  20.4s\n",
      "[CV] END model__colsample_bytree=0.7246844304357644, model__gamma=2.600340105889054, model__learning_rate=0.09200654190149193, model__max_depth=9, model__min_child_weight=2, model__n_estimators=855, model__subsample=0.9757995766256756; total time=  20.0s\n",
      "[CV] END model__colsample_bytree=0.7246844304357644, model__gamma=2.600340105889054, model__learning_rate=0.09200654190149193, model__max_depth=9, model__min_child_weight=2, model__n_estimators=855, model__subsample=0.9757995766256756; total time=  21.2s\n",
      "[CV] END model__colsample_bytree=0.8989280440549523, model__gamma=2.698460661945399, model__learning_rate=0.09801267484957722, model__max_depth=5, model__min_child_weight=9, model__n_estimators=456, model__subsample=0.9208787923016158; total time=  12.4s\n",
      "[CV] END model__colsample_bytree=0.9579309401710595, model__gamma=2.9894998940554256, model__learning_rate=0.14828113525346753, model__max_depth=8, model__min_child_weight=9, model__n_estimators=595, model__subsample=0.9378135394712606; total time=  15.3s\n",
      "[CV] END model__colsample_bytree=0.8989280440549523, model__gamma=2.698460661945399, model__learning_rate=0.09801267484957722, model__max_depth=5, model__min_child_weight=9, model__n_estimators=456, model__subsample=0.9208787923016158; total time=  12.6s\n",
      "[CV] END model__colsample_bytree=0.9579309401710595, model__gamma=2.9894998940554256, model__learning_rate=0.14828113525346753, model__max_depth=8, model__min_child_weight=9, model__n_estimators=595, model__subsample=0.9378135394712606; total time=  15.3s\n",
      "[CV] END model__colsample_bytree=0.9579309401710595, model__gamma=2.9894998940554256, model__learning_rate=0.14828113525346753, model__max_depth=8, model__min_child_weight=9, model__n_estimators=595, model__subsample=0.9378135394712606; total time=  15.5s\n",
      "[CV] END model__colsample_bytree=0.8989280440549523, model__gamma=2.698460661945399, model__learning_rate=0.09801267484957722, model__max_depth=5, model__min_child_weight=9, model__n_estimators=456, model__subsample=0.9208787923016158; total time=  12.5s\n",
      "[CV] END model__colsample_bytree=0.6298202574719083, model__gamma=4.9344346830025865, model__learning_rate=0.12583671539449862, model__max_depth=8, model__min_child_weight=8, model__n_estimators=771, model__subsample=0.6056319290860338; total time=  17.3s\n",
      "[CV] END model__colsample_bytree=0.6298202574719083, model__gamma=4.9344346830025865, model__learning_rate=0.12583671539449862, model__max_depth=8, model__min_child_weight=8, model__n_estimators=771, model__subsample=0.6056319290860338; total time=  17.0s\n",
      "[CV] END model__colsample_bytree=0.6463476238100518, model__gamma=4.315517129377968, model__learning_rate=0.10349471902413368, model__max_depth=6, model__min_child_weight=1, model__n_estimators=347, model__subsample=0.7483273008793065; total time=  12.8s\n",
      "[CV] END model__colsample_bytree=0.679536961635522, model__gamma=3.5567097637432497, model__learning_rate=0.12852633107968084, model__max_depth=7, model__min_child_weight=5, model__n_estimators=789, model__subsample=0.7433862914177091; total time=  16.5s\n",
      "[CV] END model__colsample_bytree=0.6298202574719083, model__gamma=4.9344346830025865, model__learning_rate=0.12583671539449862, model__max_depth=8, model__min_child_weight=8, model__n_estimators=771, model__subsample=0.6056319290860338; total time=  16.9s\n",
      "[CV] END model__colsample_bytree=0.6463476238100518, model__gamma=4.315517129377968, model__learning_rate=0.10349471902413368, model__max_depth=6, model__min_child_weight=1, model__n_estimators=347, model__subsample=0.7483273008793065; total time=  12.3s\n",
      "[CV] END model__colsample_bytree=0.679536961635522, model__gamma=3.5567097637432497, model__learning_rate=0.12852633107968084, model__max_depth=7, model__min_child_weight=5, model__n_estimators=789, model__subsample=0.7433862914177091; total time=  16.8s\n",
      "[CV] END model__colsample_bytree=0.679536961635522, model__gamma=3.5567097637432497, model__learning_rate=0.12852633107968084, model__max_depth=7, model__min_child_weight=5, model__n_estimators=789, model__subsample=0.7433862914177091; total time=  17.1s\n",
      "[CV] END model__colsample_bytree=0.6463476238100518, model__gamma=4.315517129377968, model__learning_rate=0.10349471902413368, model__max_depth=6, model__min_child_weight=1, model__n_estimators=347, model__subsample=0.7483273008793065; total time=  12.6s\n",
      "[CV] END model__colsample_bytree=0.610167650697638, model__gamma=0.5394571349665223, model__learning_rate=0.014714377853010139, model__max_depth=5, model__min_child_weight=4, model__n_estimators=395, model__subsample=0.878206434570451; total time=  13.8s\n",
      "[CV] END model__colsample_bytree=0.8675365010654429, model__gamma=3.329611783087483, model__learning_rate=0.09869466815615906, model__max_depth=7, model__min_child_weight=3, model__n_estimators=912, model__subsample=0.9886848381556415; total time=  18.9s\n",
      "[CV] END model__colsample_bytree=0.9395655297064336, model__gamma=3.608647605824366, model__learning_rate=0.045397737962343365, model__max_depth=7, model__min_child_weight=9, model__n_estimators=506, model__subsample=0.7710164073434198; total time=  15.7s\n",
      "[CV] END model__colsample_bytree=0.9395655297064336, model__gamma=3.608647605824366, model__learning_rate=0.045397737962343365, model__max_depth=7, model__min_child_weight=9, model__n_estimators=506, model__subsample=0.7710164073434198; total time=  15.6s\n",
      "[CV] END model__colsample_bytree=0.9395655297064336, model__gamma=3.608647605824366, model__learning_rate=0.045397737962343365, model__max_depth=7, model__min_child_weight=9, model__n_estimators=506, model__subsample=0.7710164073434198; total time=  15.6s\n",
      "[CV] END model__colsample_bytree=0.8675365010654429, model__gamma=3.329611783087483, model__learning_rate=0.09869466815615906, model__max_depth=7, model__min_child_weight=3, model__n_estimators=912, model__subsample=0.9886848381556415; total time=  19.0s\n",
      "[CV] END model__colsample_bytree=0.8675365010654429, model__gamma=3.329611783087483, model__learning_rate=0.09869466815615906, model__max_depth=7, model__min_child_weight=3, model__n_estimators=912, model__subsample=0.9886848381556415; total time=  19.2s\n",
      "[CV] END model__colsample_bytree=0.610167650697638, model__gamma=0.5394571349665223, model__learning_rate=0.014714377853010139, model__max_depth=5, model__min_child_weight=4, model__n_estimators=395, model__subsample=0.878206434570451; total time=  13.8s\n",
      "[CV] END model__colsample_bytree=0.610167650697638, model__gamma=0.5394571349665223, model__learning_rate=0.014714377853010139, model__max_depth=5, model__min_child_weight=4, model__n_estimators=395, model__subsample=0.878206434570451; total time=  14.2s\n",
      "[CV] END model__colsample_bytree=0.6873761748867334, model__gamma=2.082549739351831, model__learning_rate=0.14249203883783024, model__max_depth=6, model__min_child_weight=7, model__n_estimators=647, model__subsample=0.7425191352307899; total time=  15.7s\n",
      "[CV] END model__colsample_bytree=0.6557325817623503, model__gamma=3.0220868963890863, model__learning_rate=0.09097616369525097, model__max_depth=9, model__min_child_weight=4, model__n_estimators=824, model__subsample=0.6307919639315172; total time=  19.9s\n",
      "[CV] END model__colsample_bytree=0.6557325817623503, model__gamma=3.0220868963890863, model__learning_rate=0.09097616369525097, model__max_depth=9, model__min_child_weight=4, model__n_estimators=824, model__subsample=0.6307919639315172; total time=  20.4s\n",
      "[CV] END model__colsample_bytree=0.6557325817623503, model__gamma=3.0220868963890863, model__learning_rate=0.09097616369525097, model__max_depth=9, model__min_child_weight=4, model__n_estimators=824, model__subsample=0.6307919639315172; total time=  20.8s\n",
      "[CV] END model__colsample_bytree=0.7159005811655073, model__gamma=0.8061064362700221, model__learning_rate=0.14945464785138596, model__max_depth=9, model__min_child_weight=9, model__n_estimators=945, model__subsample=0.782613828193164; total time=  21.8s\n",
      "[CV] END model__colsample_bytree=0.7159005811655073, model__gamma=0.8061064362700221, model__learning_rate=0.14945464785138596, model__max_depth=9, model__min_child_weight=9, model__n_estimators=945, model__subsample=0.782613828193164; total time=  21.5s\n",
      "[CV] END model__colsample_bytree=0.7159005811655073, model__gamma=0.8061064362700221, model__learning_rate=0.14945464785138596, model__max_depth=9, model__min_child_weight=9, model__n_estimators=945, model__subsample=0.782613828193164; total time=  21.1s\n",
      "[CV] END model__colsample_bytree=0.6873761748867334, model__gamma=2.082549739351831, model__learning_rate=0.14249203883783024, model__max_depth=6, model__min_child_weight=7, model__n_estimators=647, model__subsample=0.7425191352307899; total time=  13.8s\n",
      "[CV] END model__colsample_bytree=0.9627313766183017, model__gamma=1.3606612469231765, model__learning_rate=0.10715351808120434, model__max_depth=5, model__min_child_weight=4, model__n_estimators=558, model__subsample=0.6027808522124762; total time=  11.4s\n",
      "[CV] END model__colsample_bytree=0.9627313766183017, model__gamma=1.3606612469231765, model__learning_rate=0.10715351808120434, model__max_depth=5, model__min_child_weight=4, model__n_estimators=558, model__subsample=0.6027808522124762; total time=  11.1s\n",
      "[CV] END model__colsample_bytree=0.6873761748867334, model__gamma=2.082549739351831, model__learning_rate=0.14249203883783024, model__max_depth=6, model__min_child_weight=7, model__n_estimators=647, model__subsample=0.7425191352307899; total time=  12.1s\n",
      "[CV] END model__colsample_bytree=0.9627313766183017, model__gamma=1.3606612469231765, model__learning_rate=0.10715351808120434, model__max_depth=5, model__min_child_weight=4, model__n_estimators=558, model__subsample=0.6027808522124762; total time=  10.9s\n",
      "Best RMSE   : 3556.96484375\n",
      "Best params :\n",
      "   model__colsample_bytree: 0.7246844304357644\n",
      "   model__gamma: 2.600340105889054\n",
      "   model__learning_rate: 0.09200654190149193\n",
      "   model__max_depth: 9\n",
      "   model__min_child_weight: 2\n",
      "   model__n_estimators: 855\n",
      "   model__subsample: 0.9757995766256756\n",
      "XGBoost Tuned Performance Metrics:\n",
      "MAE: 3621.82\n",
      "MSE: 736647168.00\n",
      "RMSE: 27141.24\n",
      "RÂ²: 0.65\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1) Daten laden / splitten\n",
    "    X_train, X_test, y_train, y_test, cat_feats, num_feats = split_data('../../../data.csv')\n",
    "    \n",
    "    # 2) Transformer\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, num_feats),\n",
    "        ('cat', categorical_transformer, cat_feats)\n",
    "    ])\n",
    "\n",
    "    # 3) XGBoost-Pipeline\n",
    "    xgb_pipeline = Pipeline([\n",
    "        ('imp_fc', ContextImputer('fuel_consumption_l_100km')),\n",
    "        ('imp_ps', ContextImputer('power_ps')),\n",
    "        ('imp_er', ContextImputer('electric_range')),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', xgb.XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=7,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    print(\"Training XGBoost model...\")\n",
    "    xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # ------------------------\n",
    "    # 1) Hyper-Parameterraum\n",
    "    # ------------------------\n",
    "    param_dist = {\n",
    "        'model__n_estimators'    : randint(300, 1000),\n",
    "        'model__learning_rate'   : uniform(0.01, 0.15),\n",
    "        'model__max_depth'       : randint(5, 10),\n",
    "        'model__subsample'       : uniform(0.6, 0.4),         # 0.6 â€“ 1.0\n",
    "        'model__colsample_bytree': uniform(0.6, 0.4),\n",
    "        'model__min_child_weight': randint(1, 10),\n",
    "        'model__gamma'           : uniform(0, 5),        \n",
    "    }\n",
    "\n",
    "    # ------------------------\n",
    "    # 2) Cross-Validation-Setup\n",
    "    # ------------------------\n",
    "    cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator = xgb_pipeline,\n",
    "        param_distributions = param_dist,\n",
    "        n_iter = 20,                  \n",
    "        scoring = 'neg_mean_absolute_error',\n",
    "        cv = cv,\n",
    "        n_jobs = -1,                   # alle Kerne\n",
    "        verbose = 2,\n",
    "        random_state = 42,\n",
    "        return_train_score = False\n",
    "    )\n",
    "\n",
    "    rs.fit(X_train, y_train, model__verbose = False)\n",
    "\n",
    "    print(\"Best RMSE   :\", -rs.best_score_)\n",
    "    print(\"Best params :\")\n",
    "    for k, v in rs.best_params_.items():\n",
    "        print(f\"   {k}: {v}\")\n",
    "\n",
    "    best_pipeline = rs.best_estimator_\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred, \"XGBoost Tuned\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_mining_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
