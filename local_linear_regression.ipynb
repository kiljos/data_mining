{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64d6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Ridge Regression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder, TargetEncoder\n",
    "from Preprocessing.imputation import get_imputation_maps, apply_imputation, ContextImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Eigene Module\n",
    "from Preprocessing.split import split_data\n",
    "from Preprocessing.preprocessing_pipeline_initial import preprocessing_pipeline\n",
    "from Preprocessing.preprocessing_pipeline_offerdesc import preprocessing_pipeline_offerdesc\n",
    "from Preprocessing.preprocessing_pipeline_impute import preprocessing_pipeline_impute\n",
    "from Preprocessing.preprocessing_pipeline_segment import preprocessing_pipeline_segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3630c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-Modell: Durchschnittspreis pro Marke\n",
      "MSE:  738802142.01\n",
      "RMSE: 27180.92\n",
      "MAE:  12561.53\n",
      "R²:   0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bibbe\\AppData\\Local\\Temp\\ipykernel_700\\4253651803.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test[\"predicted_price\"].fillna(overall_mean, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>price_in_euro</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14228</th>\n",
       "      <td>audi</td>\n",
       "      <td>57444</td>\n",
       "      <td>27229.199473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8456</th>\n",
       "      <td>audi</td>\n",
       "      <td>19990</td>\n",
       "      <td>27229.199473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210103</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>17790</td>\n",
       "      <td>18346.889412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70454</th>\n",
       "      <td>hyundai</td>\n",
       "      <td>8490</td>\n",
       "      <td>17996.688452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89888</th>\n",
       "      <td>mazda</td>\n",
       "      <td>26900</td>\n",
       "      <td>22297.727865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196446</th>\n",
       "      <td>volkswagen</td>\n",
       "      <td>4990</td>\n",
       "      <td>18346.889412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>audi</td>\n",
       "      <td>6000</td>\n",
       "      <td>27229.199473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136926</th>\n",
       "      <td>opel</td>\n",
       "      <td>17650</td>\n",
       "      <td>13991.840324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111266</th>\n",
       "      <td>mercedes-benz</td>\n",
       "      <td>36999</td>\n",
       "      <td>29615.595736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141541</th>\n",
       "      <td>opel</td>\n",
       "      <td>29990</td>\n",
       "      <td>13991.840324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44508 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                brand  price_in_euro  predicted_price\n",
       "14228            audi          57444     27229.199473\n",
       "8456             audi          19990     27229.199473\n",
       "210103     volkswagen          17790     18346.889412\n",
       "70454         hyundai           8490     17996.688452\n",
       "89888           mazda          26900     22297.727865\n",
       "...               ...            ...              ...\n",
       "196446     volkswagen           4990     18346.889412\n",
       "2558             audi           6000     27229.199473\n",
       "136926           opel          17650     13991.840324\n",
       "111266  mercedes-benz          36999     29615.595736\n",
       "141541           opel          29990     13991.840324\n",
       "\n",
       "[44508 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 0 - Baseline: Durchschnittspreis pro Automarke\n",
    "\n",
    "def average_price_per_brand(df, price_column=\"price_in_euro\", brand_column=\"brand\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Baseline-Modell mit Stratification:\n",
    "    - Durchschnittspreis pro Marke im Training\n",
    "    - Vorhersage auf Testdaten\n",
    "    - Evaluation mit MSE, RMSE, MAE, R²\n",
    "    \"\"\"\n",
    "\n",
    "    # Entferne Marken, die weniger als 2x vorkommen\n",
    "    brand_counts = df[brand_column].value_counts()\n",
    "    valid_brands = brand_counts[brand_counts >= 2].index\n",
    "    df = df[df[brand_column].isin(valid_brands)]\n",
    "    \n",
    "    # Train-Test-Split mit Stratifikation auf Marke\n",
    "    df_train, df_test = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        stratify=df[brand_column],\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Durchschnittspreis pro Marke im Training\n",
    "    brand_avg = df_train.groupby(brand_column)[price_column].mean()\n",
    "\n",
    "    # Vorhersage: Testdaten bekommen den Markenmittelwert\n",
    "    df_test = df_test.copy()\n",
    "    df_test[\"predicted_price\"] = df_test[brand_column].map(brand_avg)\n",
    "\n",
    "    # Fallback: Wenn Marke nicht im Training war, setze Gesamtmittelwert\n",
    "    overall_mean = df_train[price_column].mean()\n",
    "    df_test[\"predicted_price\"].fillna(overall_mean, inplace=True)\n",
    "\n",
    "    # Evaluation\n",
    "    y_true = df_test[price_column]\n",
    "    y_pred = df_test[\"predicted_price\"]\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(\"Baseline-Modell: Durchschnittspreis pro Marke\")\n",
    "    print(f\"MSE:  {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE:  {mae:.2f}\")\n",
    "    print(f\"R²:   {r2:.2f}\")\n",
    "\n",
    "    return df_test[[brand_column, price_column, \"predicted_price\"]]\n",
    "\n",
    "# Beispiel-Anwendung:\n",
    "df = preprocessing_pipeline_impute(path='data.csv') \n",
    "average_price_per_brand(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44685f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline-Modell: Durchschnittspreis pro Modell\n",
      "MSE:  320008645.18\n",
      "RMSE: 17888.79\n",
      "MAE:  8573.58\n",
      "R²:   0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bibbe\\AppData\\Local\\Temp\\ipykernel_700\\2650455354.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test[\"predicted_price\"].fillna(overall_mean, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>price_in_euro</th>\n",
       "      <th>predicted_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>193804</th>\n",
       "      <td>Volkswagen Passat</td>\n",
       "      <td>13490</td>\n",
       "      <td>13229.065455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>Audi A3</td>\n",
       "      <td>6399</td>\n",
       "      <td>17508.785036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99564</th>\n",
       "      <td>Mercedes-Benz Sprinter</td>\n",
       "      <td>14399</td>\n",
       "      <td>23509.586957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6989</th>\n",
       "      <td>Audi A8</td>\n",
       "      <td>23999</td>\n",
       "      <td>35288.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134795</th>\n",
       "      <td>Opel Grandland</td>\n",
       "      <td>17490</td>\n",
       "      <td>28746.865979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150931</th>\n",
       "      <td>Porsche 992</td>\n",
       "      <td>229900</td>\n",
       "      <td>193534.076503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171633</th>\n",
       "      <td>Skoda Superb</td>\n",
       "      <td>17498</td>\n",
       "      <td>25391.120719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145559</th>\n",
       "      <td>Peugeot 2008</td>\n",
       "      <td>19790</td>\n",
       "      <td>19285.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14395</th>\n",
       "      <td>Audi A6</td>\n",
       "      <td>38770</td>\n",
       "      <td>24385.093285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220715</th>\n",
       "      <td>Volvo V60</td>\n",
       "      <td>29900</td>\n",
       "      <td>29766.674847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44485 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model  price_in_euro  predicted_price\n",
       "193804       Volkswagen Passat          13490     13229.065455\n",
       "6023                   Audi A3           6399     17508.785036\n",
       "99564   Mercedes-Benz Sprinter          14399     23509.586957\n",
       "6989                   Audi A8          23999     35288.578947\n",
       "134795          Opel Grandland          17490     28746.865979\n",
       "...                        ...            ...              ...\n",
       "150931             Porsche 992         229900    193534.076503\n",
       "171633            Skoda Superb          17498     25391.120719\n",
       "145559            Peugeot 2008          19790     19285.600000\n",
       "14395                  Audi A6          38770     24385.093285\n",
       "220715               Volvo V60          29900     29766.674847\n",
       "\n",
       "[44485 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Version 0.1 - Baseline: Durchschnittspreis pro Modell\n",
    "\n",
    "def average_price_per_model(df, price_column=\"price_in_euro\", model_column=\"model\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Baseline-Modell mit Stratification:\n",
    "    - Durchschnittspreis pro Modell im Training\n",
    "    - Vorhersage auf Testdaten\n",
    "    - Evaluation mit MSE, RMSE, MAE, R²\n",
    "    \"\"\"\n",
    "\n",
    "    # Entferne Marken, die weniger als 2x vorkommen\n",
    "    model_counts = df[model_column].value_counts()\n",
    "    valid_models = model_counts[model_counts >= 2].index\n",
    "    df = df[df[model_column].isin(valid_models)]\n",
    "    \n",
    "    # Train-Test-Split mit Stratifikation auf Marke\n",
    "    df_train, df_test = train_test_split(\n",
    "        df,\n",
    "        test_size=test_size,\n",
    "        stratify=df[model_column],\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Durchschnittspreis pro Marke im Training\n",
    "    brand_avg = df_train.groupby(model_column)[price_column].mean()\n",
    "\n",
    "    # Vorhersage: Testdaten bekommen den Modellmittelwert\n",
    "    df_test = df_test.copy()\n",
    "    df_test[\"predicted_price\"] = df_test[model_column].map(brand_avg)\n",
    "\n",
    "    # Fallback: Wenn Modell nicht im Training war, setze Gesamtmittelwert\n",
    "    overall_mean = df_train[price_column].mean()\n",
    "    df_test[\"predicted_price\"].fillna(overall_mean, inplace=True)\n",
    "\n",
    "    # Evaluation\n",
    "    y_true = df_test[price_column]\n",
    "    y_pred = df_test[\"predicted_price\"]\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(\"Baseline-Modell: Durchschnittspreis pro Modell\")\n",
    "    print(f\"MSE:  {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE:  {mae:.2f}\")\n",
    "    print(f\"R²:   {r2:.2f}\")\n",
    "\n",
    "    return df_test[[model_column, price_column, \"predicted_price\"]]\n",
    "\n",
    "# Beispiel-Anwendung:\n",
    "df = preprocessing_pipeline_impute(path='data.csv') \n",
    "average_price_per_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee911b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      " Bestes n_neighbors: 30\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('model', LocalLinearRegressor(n_neighbors=30))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__n_neighbors': 30}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-193358.0392562988\n",
      "Test MSE: 63184540990.00\n",
      "Test RMSE: 251365.35\n",
      "Test MAE: 20022.37\n",
      "Test R²: -59.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 1.0 - Local Linear Regression: Grid Search + Label Encoding, k = 3 / 30\n",
    "\n",
    "class LocalLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)  # Falls X ein Numpy-Array ist\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Eigentliche Funktion\n",
    "def main_local_linear_regression_with_gridsearch():\n",
    "    # Preprocessing \n",
    "    df = preprocessing_pipeline(path = 'data.csv')  \n",
    "    # Nimm ersten 10.000 Zeilen zufällig\n",
    "    df = df.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "    # Train - Test Split\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df) \n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        # NaN Werte\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        # Alle anderen Werte\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalLinearRegressor()  \n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [3,30]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    # Quasi intern erledigt von scikit learn an dieser Stelle:\n",
    "    # X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    # model.fit(X_train_transformed, y_train)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors:\", grid_search.best_params_['model__n_neighbors'])\n",
    "\n",
    "    # Printe alle Ergebnisse\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewerte\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Berechnungen\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Ausgabe\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_linear_regression_with_gridsearch()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c063a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      " Bestes n_neighbors: 200\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('model', LocalLinearRegressor(n_neighbors=200))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__n_neighbors': 200}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-14213.445815765472\n",
      "Test MSE: 152282049.77\n",
      "Test RMSE: 12340.26\n",
      "Test MAE: 3930.85\n",
      "Test R²: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 1.0.1 - Local Linear Regression: Grid Search + Label Encoding\n",
    "\n",
    "class LocalLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)  # Falls X ein Numpy-Array ist\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Eigentliche Funktion\n",
    "def main_local_linear_regression_with_gridsearch_0():\n",
    "    # Preprocessing \n",
    "    df = preprocessing_pipeline(path = 'data.csv')  \n",
    "    \n",
    "    \n",
    "    # Train - Test Split\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df) \n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        # NaN Werte\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        # Alle anderen Werte\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalLinearRegressor()  \n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [10, 25, 50, 100, 200, 500]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    # Quasi intern erledigt von scikit learn an dieser Stelle:\n",
    "    # X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    # model.fit(X_train_transformed, y_train)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors:\", grid_search.best_params_['model__n_neighbors'])\n",
    "\n",
    "    # Printe alle Ergebnisse\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewerte\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Berechnungen\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Ausgabe\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_linear_regression_with_gridsearch_0()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48c09b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      " Bestes n_neighbors: 200\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type',\n",
      "                                                   'offer_description',\n",
      "                                                   'offer_description_cleaned'])])),\n",
      "                ('model', LocalLinearRegressor(n_neighbors=200))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__n_neighbors': 200}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-25499.22761340385\n",
      "Test MSE: 535502134.85\n",
      "Test RMSE: 23140.92\n",
      "Test MAE: 11712.22\n",
      "Test R²: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 1.0.2 - Local Linear Regression: Grid Search + Label Encoding + offer-decrrption\n",
    "\n",
    "class LocalLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)  # Falls X ein Numpy-Array ist\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Eigentliche Funktion\n",
    "def main_local_linear_regression_with_gridsearch_0():\n",
    "    # Preprocessing \n",
    "    df = preprocessing_pipeline(path = 'data.csv')  \n",
    "    df = preprocessing_pipeline_offerdesc(df)\n",
    "\n",
    "    # Train - Test Split\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df) \n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        # NaN Werte\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        # Alle anderen Werte\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalLinearRegressor()  \n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [200]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    # Quasi intern erledigt von scikit learn an dieser Stelle:\n",
    "    # X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    # model.fit(X_train_transformed, y_train)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors:\", grid_search.best_params_['model__n_neighbors'])\n",
    "\n",
    "    # Printe alle Ergebnisse\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewerte\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Berechnungen\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Ausgabe\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_linear_regression_with_gridsearch_0()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf879f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n        X,\n    ...<3 lines>...\n        routed_params=routed_params,\n    )\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ~~~~^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ~~~~~~~~~~~~~~~~~~~~~~~^\n        Xt, y, **last_step_params[\"fit_transform\"]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_target_encoder.py\", line 273, in fit_transform\n    X_out = np.empty(\n        (X_ordinal.shape[0], X_ordinal.shape[1] * len(self.classes_)),\n        dtype=np.float64,\n    )\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 48.2 GiB for an array with shape (109969, 58795) and data type float64\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n        X,\n    ...<3 lines>...\n        routed_params=routed_params,\n    )\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ~~~~^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ~~~~~~~~~~~~~~~~~~~~~~~^\n        Xt, y, **last_step_params[\"fit_transform\"]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_target_encoder.py\", line 273, in fit_transform\n    X_out = np.empty(\n        (X_ordinal.shape[0], X_ordinal.shape[1] * len(self.classes_)),\n        dtype=np.float64,\n    )\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 48.1 GiB for an array with shape (109969, 58675) and data type float64\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n        X,\n    ...<3 lines>...\n        routed_params=routed_params,\n    )\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ~~~~^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ~~~~~~~~~~~~~~~~~~~~~~~^\n        Xt, y, **last_step_params[\"fit_transform\"]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_target_encoder.py\", line 273, in fit_transform\n    X_out = np.empty(\n        (X_ordinal.shape[0], X_ordinal.shape[1] * len(self.classes_)),\n        dtype=np.float64,\n    )\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 48.0 GiB for an array with shape (109970, 58585) and data type float64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Aufruf der Funktion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m best_model = \u001b[43mmain_local_linear_regression_with_gridsearch_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mmain_local_linear_regression_with_gridsearch_1\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     69\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     70\u001b[39m     full_pipeline,\n\u001b[32m     71\u001b[39m     param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     76\u001b[39m )\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarte Grid Search...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Bestes n_neighbors:\u001b[39m\u001b[33m\"\u001b[39m, grid_search.best_params_[\u001b[33m'\u001b[39m\u001b[33mmodel__n_neighbors\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Printe alle Ergebnisse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    996\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    997\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    998\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m    999\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1004\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    511\u001b[39m     all_fits_failed_message = (\n\u001b[32m    512\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    520\u001b[39m     some_fits_failed_message = (\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 3 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n        X,\n    ...<3 lines>...\n        routed_params=routed_params,\n    )\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ~~~~^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ~~~~~~~~~~~~~~~~~~~~~~~^\n        Xt, y, **last_step_params[\"fit_transform\"]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_target_encoder.py\", line 273, in fit_transform\n    X_out = np.empty(\n        (X_ordinal.shape[0], X_ordinal.shape[1] * len(self.classes_)),\n        dtype=np.float64,\n    )\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 48.2 GiB for an array with shape (109969, 58795) and data type float64\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n        X,\n    ...<3 lines>...\n        routed_params=routed_params,\n    )\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ~~~~^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ~~~~~~~~~~~~~~~~~~~~~~~^\n        Xt, y, **last_step_params[\"fit_transform\"]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_target_encoder.py\", line 273, in fit_transform\n    X_out = np.empty(\n        (X_ordinal.shape[0], X_ordinal.shape[1] * len(self.classes_)),\n        dtype=np.float64,\n    )\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 48.1 GiB for an array with shape (109969, 58675) and data type float64\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1001, in fit_transform\n    result = self._call_func_on_transformers(\n        X,\n    ...<3 lines>...\n        routed_params=routed_params,\n    )\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 910, in _call_func_on_transformers\n    return Parallel(n_jobs=self.n_jobs)(jobs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n    return output if self.return_generator else list(output)\n                                                ~~~~^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py\", line 730, in fit_transform\n    return last_step.fit_transform(\n           ~~~~~~~~~~~~~~~~~~~~~~~^\n        Xt, y, **last_step_params[\"fit_transform\"]\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\preprocessing\\_target_encoder.py\", line 273, in fit_transform\n    X_out = np.empty(\n        (X_ordinal.shape[0], X_ordinal.shape[1] * len(self.classes_)),\n        dtype=np.float64,\n    )\nnumpy._core._exceptions._ArrayMemoryError: Unable to allocate 48.0 GiB for an array with shape (109970, 58585) and data type float64\n"
     ]
    }
   ],
   "source": [
    "# Version 1.1 - Local Linear Regression: Grid Search + Target Encoding\n",
    "\n",
    "class LocalLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)  # Falls X ein Numpy-Array ist\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Eigentliche Funktion\n",
    "def main_local_linear_regression_with_gridsearch_1():\n",
    "    # Preprocessing \n",
    "    df = preprocessing_pipeline(path = 'data.csv')  \n",
    "    # Train - Test Split\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df) \n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        # NaN Werte\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        # Alle anderen Werte\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('target', TargetEncoder())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalLinearRegressor()  \n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [200]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors:\", grid_search.best_params_['model__n_neighbors'])\n",
    "\n",
    "    # Printe alle Ergebnisse\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewerte\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Berechnungen\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Ausgabe\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_linear_regression_with_gridsearch_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ae6934d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 113\u001b[39m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# Aufruf der Funktion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m best_model = \u001b[43mmain_local_linear_regression_with_gridsearch_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 79\u001b[39m, in \u001b[36mmain_local_linear_regression_with_gridsearch_2\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     69\u001b[39m grid_search = GridSearchCV(\n\u001b[32m     70\u001b[39m     full_pipeline,\n\u001b[32m     71\u001b[39m     param_grid,\n\u001b[32m   (...)\u001b[39m\u001b[32m     75\u001b[39m     verbose=\u001b[32m2\u001b[39m\n\u001b[32m     76\u001b[39m )\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarte Grid Search...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Bestes n_neighbors:\u001b[39m\u001b[33m\"\u001b[39m, grid_search.best_params_[\u001b[33m'\u001b[39m\u001b[33mmodel__n_neighbors\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Printe alle Ergebnisse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1569\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1570\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Version 1.2 - Local Linear Regression: Grid Search + One-Hot Encoding\n",
    "\n",
    "class LocalLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)  # Falls X ein Numpy-Array ist\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Eigentliche Funktion\n",
    "def main_local_linear_regression_with_gridsearch_2():\n",
    "    # Preprocessing \n",
    "    df = preprocessing_pipeline(path = 'data.csv')  \n",
    "    # Train - Test Split\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df) \n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        # NaN Werte\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        # Alle anderen Werte\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalLinearRegressor()  \n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100,200]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors:\", grid_search.best_params_['model__n_neighbors'])\n",
    "\n",
    "    # Printe alle Ergebnisse\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewerte\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Berechnungen\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Ausgabe\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_linear_regression_with_gridsearch_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87ea8dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "\n",
      " Bestes n_neighbors: 200\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   RobustScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('model', LocalLinearRegressor(n_neighbors=200))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__n_neighbors': 200}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-13505.39443144958\n",
      "Test MSE: 147779734.58\n",
      "Test RMSE: 12156.47\n",
      "Test MAE: 3950.54\n",
      "Test R²: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 1.3 - Local Linear Regression: Grid Search + Label Encoding + Robust Scaling\n",
    "\n",
    "class LocalLinearRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)  # Falls X ein Numpy-Array ist\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Eigentliche Funktion\n",
    "def main_local_linear_regression_with_gridsearch_3():\n",
    "    # Preprocessing \n",
    "    df = preprocessing_pipeline(path = 'data.csv')  \n",
    "    # Train - Test Split\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df) \n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        # NaN Werte\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        # Alle anderen Werte\n",
    "        ('scaler', RobustScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalLinearRegressor()  \n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100,200]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors:\", grid_search.best_params_['model__n_neighbors'])\n",
    "\n",
    "    # Printe alle Ergebnisse\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewerte\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Berechnungen\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Ausgabe\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_linear_regression_with_gridsearch_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be0abefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      "Bestes Modell:\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   RobustScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('model', LocalLassoRegressor(n_neighbors=200))])\n",
      "\n",
      "Beste Hyperparameter:\n",
      "{'model__alpha': 1.0, 'model__n_neighbors': 200}\n",
      "\n",
      "Bestes Cross-Validation Ergebnis (neg_root_mse):\n",
      "-13504.460101420767\n",
      "Test MSE: 146339427.72\n",
      "Test RMSE: 12097.08\n",
      "Test MAE: 3943.80\n",
      "Test R²: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 2 - Local Lasso Regression: Grid Search + Label + Standard\n",
    "\n",
    "class LocalLassoRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Lasso(alpha=self.alpha, max_iter=10000)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_lasso_regression_with_gridsearch():\n",
    "    df = preprocessing_pipeline(path = 'data.csv')\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', RobustScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    model = LocalLassoRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100,200],\n",
    "        'model__alpha': [0.01, 0.1, 1.0]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBestes Modell:\")\n",
    "    print(grid_search.best_estimator_)\n",
    "    print(\"\\nBeste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\\nBestes Cross-Validation Ergebnis (neg_root_mse):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_lasso_regression_with_gridsearch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5a81f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 0.1, 'model__n_neighbors': 100}\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   RobustScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('model', LocalRidgeRegressor(alpha=0.1, n_neighbors=100))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__alpha': 0.1, 'model__n_neighbors': 100}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-12986.54660339479\n",
      "Test MSE: 134506710.21\n",
      "Test RMSE: 11597.70\n",
      "Test MAE: 3748.72\n",
      "Test R²: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 3.0 - Local Ridge Regression: Grid Search + Label + Robust\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch():\n",
    "    # Preprocessing\n",
    "    df = preprocessing_pipeline(path = 'data.csv')\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', RobustScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100, 200],\n",
    "        'model__alpha': [0.1, 1.0, 10.0]  # Ridge Regularisierung (klein/mittel/stark)\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewertung\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dd3422a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 1.0, 'model__n_neighbors': 100}\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('model', LocalRidgeRegressor(n_neighbors=100))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__alpha': 1.0, 'model__n_neighbors': 100}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-12958.764305468134\n",
      "Test MSE: 134731937.91\n",
      "Test RMSE: 11607.41\n",
      "Test MAE: 3710.83\n",
      "Test R²: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 3.1 - Local Ridge Regression: Grid Search + Label + Standard\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch_1():\n",
    "    # Preprocessing\n",
    "    df = preprocessing_pipeline(path = 'data.csv')\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100, 200],\n",
    "        'model__alpha': [0.1, 1.0, 10.0]  # Ridge Regularisierung (klein/mittel/stark)\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewertung\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch_1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc0f9382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 1.0, 'model__n_neighbors': 50}\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('imp_fc',\n",
      "                 ContextImputer(target_col='fuel_consumption_l_100km')),\n",
      "                ('imp_ps', ContextImputer(target_col='power_ps')),\n",
      "                ('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('model', LocalRidgeRegressor(n_neighbors=50))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__alpha': 1.0, 'model__n_neighbors': 50}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-15050.926698293084\n",
      "Test MSE: 104368045.80\n",
      "Test RMSE: 10216.07\n",
      "Test MAE: 3539.70\n",
      "Test R²: 0.90\n",
      "\n",
      "--- Evaluation nach fuel_type ---\n",
      "\n",
      "Fuel Type: Diesel\n",
      "  RMSE: 7747.09\n",
      "  MAE:  3368.92\n",
      "  R²:   0.81\n",
      "\n",
      "Fuel Type: Petrol\n",
      "  RMSE: 11456.78\n",
      "  MAE:  3643.24\n",
      "  R²:   0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 3.2 - Local Ridge Regression: Grid Search + Label + Standard + Imputation (k = 50 / 100)\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch_2():\n",
    "    # Preprocessing\n",
    "    df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('imp_fc', ContextImputer('fuel_consumption_l_100km')),\n",
    "        ('imp_ps', ContextImputer('power_ps')),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [50, 100],\n",
    "        'model__alpha': [0.1, 1.0, 10.0]  # Ridge Regularisierung (klein/mittel/stark)\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewertung\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    print(\"\\n--- Evaluation nach fuel_type ---\")\n",
    "    X_test_with_fuel = X_test.copy()\n",
    "    X_test_with_fuel['fuel_type'] = df.loc[X_test.index, 'fuel_type']\n",
    "    y_test_series = pd.Series(y_test, index=X_test.index)\n",
    "    y_pred_series = pd.Series(y_pred, index=X_test.index)\n",
    "\n",
    "    for fuel in X_test_with_fuel['fuel_type'].unique():\n",
    "        mask = X_test_with_fuel['fuel_type'] == fuel\n",
    "        y_true_fuel = y_test_series[mask]\n",
    "        y_pred_fuel = y_pred_series[mask]\n",
    "\n",
    "        mse_fuel = mean_squared_error(y_true_fuel, y_pred_fuel)\n",
    "        rmse_fuel = mse_fuel ** 0.5\n",
    "        mae_fuel = mean_absolute_error(y_true_fuel, y_pred_fuel)\n",
    "        r2_fuel = r2_score(y_true_fuel, y_pred_fuel)\n",
    "\n",
    "        print(f\"\\nFuel Type: {fuel}\")\n",
    "        print(f\"  RMSE: {rmse_fuel:.2f}\")\n",
    "        print(f\"  MAE:  {mae_fuel:.2f}\")\n",
    "        print(f\"  R²:   {r2_fuel:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4c39792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor Imputation:\n",
      "fuel_consumption:\n",
      "12967 in X_train\n",
      "3233 in X_test\n",
      "power_ps:\n",
      "61 in X_train\n",
      "11 in X_test\n",
      "------------------------------\n",
      "Fehlende Werte nach Imputation:\n",
      "fuel_consumption:\n",
      "88 in X_train\n",
      "26 in X_test\n",
      "power_ps:\n",
      "1 in X_train\n",
      "0 in X_test\n",
      "------------------------------\n",
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      "Bestes Modell:\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type'])])),\n",
      "                ('pca', PCA(n_components=0.9)),\n",
      "                ('model', LocalRidgeRegressor(alpha=10.0, n_neighbors=100))])\n",
      "\n",
      "Beste Hyperparameter:\n",
      "{'model__alpha': 10.0, 'model__n_neighbors': 100}\n",
      "\n",
      "Bestes CV-Ergebnis (neg RMSE):\n",
      "-21714.589374262392\n",
      "Test MSE: 311271321.80\n",
      "Test RMSE: 17642.88\n",
      "Test MAE: 7677.28\n",
      "Test R²: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 3.3 - Local Ridge Regression: Grid Search + Label + Standard + PCA\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch_3():\n",
    "    # Preprocessing\n",
    "    df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    print(\"Fehlende Werte vor Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "    \n",
    "    # Mapping aus dem Trainingsset lernen\n",
    "    fuel_maps = get_imputation_maps(X_train, target_col='fuel_consumption_l_100km')\n",
    "    ps_maps = get_imputation_maps(X_train, target_col='power_ps')\n",
    "\n",
    "    \n",
    "    # Mapping auf Trainings- und Testdaten anwenden\n",
    "    X_train = apply_imputation(X_train, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_train = apply_imputation(X_train, target_col='power_ps', maps=ps_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='power_ps', maps=ps_maps)\n",
    "\n",
    "\n",
    "    print(\"Fehlende Werte nach Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline inklusive PCA\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('pca', PCA(n_components=0.9)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100, 200],\n",
    "        'model__alpha': [0.1, 1.0, 10.0]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nBestes Modell:\")\n",
    "    print(grid_search.best_estimator_)\n",
    "    print(\"\\nBeste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\\nBestes CV-Ergebnis (neg RMSE):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Funktion starten\n",
    "best_model = main_local_ridge_regression_with_gridsearch_3()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d664ec63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor Imputation:\n",
      "fuel_consumption:\n",
      "12967 in X_train\n",
      "3233 in X_test\n",
      "power_ps:\n",
      "61 in X_train\n",
      "11 in X_test\n",
      "------------------------------\n",
      "Fehlende Werte nach Imputation:\n",
      "fuel_consumption:\n",
      "88 in X_train\n",
      "26 in X_test\n",
      "power_ps:\n",
      "1 in X_train\n",
      "0 in X_test\n",
      "------------------------------\n",
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 1.0, 'model__n_neighbors': 100}\n",
      "\n",
      "Test MSE: 123675406.54\n",
      "Test RMSE: 11120.94\n",
      "Test MAE: 3264.85\n",
      "Test R²: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 3.4 - Local Ridge Regression: Grid Search + Label + Standard + Log Transformation\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch():\n",
    "   # Preprocessing\n",
    "    df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    print(\"Fehlende Werte vor Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "    \n",
    "    # Mapping aus dem Trainingsset lernen\n",
    "    fuel_maps = get_imputation_maps(X_train, target_col='fuel_consumption_l_100km')\n",
    "    ps_maps = get_imputation_maps(X_train, target_col='power_ps')\n",
    "\n",
    "    \n",
    "    # Mapping auf Trainings- und Testdaten anwenden\n",
    "    X_train = apply_imputation(X_train, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_train = apply_imputation(X_train, target_col='power_ps', maps=ps_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='power_ps', maps=ps_maps)\n",
    "\n",
    "\n",
    "    print(\"Fehlende Werte nach Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "\n",
    "    # Log-Transformation der Zielvariable\n",
    "    y_train_log = np.log1p(y_train)  # log(1 + y)\n",
    "    y_test_log = np.log1p(y_test)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100, 200],\n",
    "        'model__alpha': [0.1, 1.0, 10.0]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train_log)  # <-- Trainiere auf log(y)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Bewertung\n",
    "    y_pred_log = best_model.predict(X_test)  # Vorhersage im Log-Raum\n",
    "    y_pred = np.expm1(y_pred_log)  # Rücktransformation zu echtem Preis\n",
    "    y_test_real = np.expm1(y_test_log)\n",
    "\n",
    "    mse = mean_squared_error(y_test_real, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test_real, y_pred)\n",
    "    r2 = r2_score(y_test_real, y_pred)\n",
    "\n",
    "    print(f\"\\nTest MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9b686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFE Funktion\n",
    "\n",
    "def run_rfe_on_preprocessed(df, target_col, preprocessor):\n",
    "    \"\"\"\n",
    "    Führt RFE auf einem DataFrame mit Zielspalte durch.\n",
    "    Erwartet, dass der Preprocessor bereits korrekt definiert wurde.\n",
    "\n",
    "    Ergebnis:\n",
    "    pd.DataFrame: Feature-reduziertes DataFrame\n",
    "    list: Liste der ausgewählten Features\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    import pandas as pd\n",
    "\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Preprocessing anwenden\n",
    "    X_proc = preprocessor.fit_transform(X)\n",
    "    feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "    # RFE mit Ridge\n",
    "    selector = RFECV(estimator=Ridge(), cv=3, scoring='neg_root_mean_squared_error')\n",
    "    selector.fit(X_proc, y)\n",
    "\n",
    "    selected_features = feature_names[selector.support_]\n",
    "    removed_features = feature_names[~selector.support_]\n",
    "\n",
    "    X_reduced = selector.transform(X_proc)\n",
    "    df_reduced = pd.DataFrame(X_reduced, columns=selected_features)\n",
    "    df_reduced[target_col] = y.reset_index(drop=True)\n",
    "\n",
    "    print(f\"RFE ausgewählt: {len(selected_features)} Features\")\n",
    "    print(\"Behaltene Features:\")\n",
    "    print(selected_features)\n",
    "\n",
    "    print(\"Entfernte Features:\")\n",
    "    print(removed_features)\n",
    "\n",
    "    return df_reduced, selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba7005e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor Imputation:\n",
      "fuel_consumption:\n",
      "12967 in X_train\n",
      "3233 in X_test\n",
      "power_ps:\n",
      "61 in X_train\n",
      "11 in X_test\n",
      "------------------------------\n",
      "Fehlende Werte nach Imputation:\n",
      "fuel_consumption:\n",
      "88 in X_train\n",
      "26 in X_test\n",
      "power_ps:\n",
      "1 in X_train\n",
      "0 in X_test\n",
      "------------------------------\n",
      "✅ RFE ausgewählt: 9 Features\n",
      "\n",
      "🟢 Behaltene Features:\n",
      "['num__year' 'num__power_ps' 'num__fuel_consumption_l_100km'\n",
      " 'num__mileage_in_km' 'cat__brand' 'cat__model' 'cat__color'\n",
      " 'cat__transmission_type' 'cat__fuel_type']\n",
      "\n",
      "🔴 Entfernte Features:\n",
      "[]\n",
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 0.1, 'model__n_neighbors': 100}\n",
      "\n",
      "Test MSE: 129057839.81\n",
      "Test RMSE: 11360.36\n",
      "Test MAE: 3714.54\n",
      "Test R²: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 4.1. - Version 3.2. + RFE\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch():\n",
    "   # Preprocessing\n",
    "    df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    print(\"Fehlende Werte vor Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "    \n",
    "    # Mapping aus dem Trainingsset lernen\n",
    "    fuel_maps = get_imputation_maps(X_train, target_col='fuel_consumption_l_100km')\n",
    "    ps_maps = get_imputation_maps(X_train, target_col='power_ps')\n",
    "\n",
    "    \n",
    "    # Mapping auf Trainings- und Testdaten anwenden\n",
    "    X_train = apply_imputation(X_train, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_train = apply_imputation(X_train, target_col='power_ps', maps=ps_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='power_ps', maps=ps_maps)\n",
    "\n",
    "\n",
    "    print(\"Fehlende Werte nach Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('label_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # RFE vorbereiten\n",
    "    X_train_df = X_train.copy()\n",
    "    X_train_df['target'] = y_train\n",
    "    df = run_rfe_on_preprocessed(X_train_df, 'target', preprocessor)\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100],\n",
    "        'model__alpha': [0.1]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Bewertung\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nTest MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8341f62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor Imputation:\n",
      "fuel_consumption:\n",
      "12967 in X_train\n",
      "3233 in X_test\n",
      "power_ps:\n",
      "61 in X_train\n",
      "11 in X_test\n",
      "------------------------------\n",
      "Fehlende Werte nach Imputation:\n",
      "fuel_consumption:\n",
      "88 in X_train\n",
      "26 in X_test\n",
      "power_ps:\n",
      "1 in X_train\n",
      "0 in X_test\n",
      "------------------------------\n",
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 1, 'model__n_neighbors': 300}\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km', 'has_acc',\n",
      "                                                   'has_additional_motortechnology',\n",
      "                                                   'has_all_wheel_drive',\n",
      "                                                   'has_assistence_systems',\n",
      "                                                   'has_dab_radio',\n",
      "                                                   'has_diesel_particel...\n",
      "                                                   'has_tuev', 'is_cabrio',\n",
      "                                                   'is_combi', 'is_coupe']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type',\n",
      "                                                   'offer_description',\n",
      "                                                   'offer_description_cleaned'])])),\n",
      "                ('model', LocalRidgeRegressor(alpha=1, n_neighbors=300))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__alpha': 1, 'model__n_neighbors': 300}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-27342.25204996906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 767821508.42\n",
      "Test RMSE: 27709.59\n",
      "Test MAE: 16833.36\n",
      "Test R²: 0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 4.2 - Local Ridge Regression: Best Combo from 3 -> 3.2 + Offer Description\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch_2():\n",
    "    # Preprocessing\n",
    "    df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "    df = preprocessing_pipeline_offerdesc(df)\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    print(\"Fehlende Werte vor Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "    \n",
    "    # Mapping aus dem Trainingsset lernen\n",
    "    fuel_maps = get_imputation_maps(X_train, target_col='fuel_consumption_l_100km')\n",
    "    ps_maps = get_imputation_maps(X_train, target_col='power_ps')\n",
    "\n",
    "    \n",
    "    # Mapping auf Trainings- und Testdaten anwenden\n",
    "    X_train = apply_imputation(X_train, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_train = apply_imputation(X_train, target_col='power_ps', maps=ps_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='power_ps', maps=ps_maps)\n",
    "\n",
    "\n",
    "    print(\"Fehlende Werte nach Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [300],\n",
    "        'model__alpha': [1]  # Ridge Regularisierung (klein/mittel/stark)\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewertung\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e76bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>color</th>\n",
       "      <th>year</th>\n",
       "      <th>price_in_euro</th>\n",
       "      <th>power_ps</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>fuel_consumption_l_100km</th>\n",
       "      <th>mileage_in_km</th>\n",
       "      <th>...</th>\n",
       "      <th>has_heated_seats</th>\n",
       "      <th>has_leather_interior</th>\n",
       "      <th>has_navigation</th>\n",
       "      <th>has_panoramic_roof</th>\n",
       "      <th>has_sport_features</th>\n",
       "      <th>has_trailer_hitch</th>\n",
       "      <th>has_tuev</th>\n",
       "      <th>is_cabrio</th>\n",
       "      <th>is_combi</th>\n",
       "      <th>is_coupe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alfa-romeo</td>\n",
       "      <td>Alfa Romeo GTV</td>\n",
       "      <td>red</td>\n",
       "      <td>1995</td>\n",
       "      <td>1300</td>\n",
       "      <td>201.0</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>10.9</td>\n",
       "      <td>160500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alfa-romeo</td>\n",
       "      <td>Alfa Romeo 164</td>\n",
       "      <td>black</td>\n",
       "      <td>1995</td>\n",
       "      <td>24900</td>\n",
       "      <td>260.0</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alfa-romeo</td>\n",
       "      <td>Alfa Romeo Spider</td>\n",
       "      <td>black</td>\n",
       "      <td>1995</td>\n",
       "      <td>5900</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alfa-romeo</td>\n",
       "      <td>Alfa Romeo Spider</td>\n",
       "      <td>black</td>\n",
       "      <td>1995</td>\n",
       "      <td>4900</td>\n",
       "      <td>150.0</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>9.5</td>\n",
       "      <td>189500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alfa-romeo</td>\n",
       "      <td>Alfa Romeo 164</td>\n",
       "      <td>red</td>\n",
       "      <td>1996</td>\n",
       "      <td>17950</td>\n",
       "      <td>179.0</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>7.2</td>\n",
       "      <td>96127.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand              model  color  year  price_in_euro  power_ps  \\\n",
       "0  alfa-romeo     Alfa Romeo GTV    red  1995           1300     201.0   \n",
       "1  alfa-romeo     Alfa Romeo 164  black  1995          24900     260.0   \n",
       "2  alfa-romeo  Alfa Romeo Spider  black  1995           5900     150.0   \n",
       "3  alfa-romeo  Alfa Romeo Spider  black  1995           4900     150.0   \n",
       "4  alfa-romeo     Alfa Romeo 164    red  1996          17950     179.0   \n",
       "\n",
       "  transmission_type fuel_type  fuel_consumption_l_100km  mileage_in_km  ...  \\\n",
       "0            Manual    Petrol                      10.9       160500.0  ...   \n",
       "1            Manual    Petrol                       NaN       190000.0  ...   \n",
       "2           Unknown    Petrol                       NaN       129000.0  ...   \n",
       "3            Manual    Petrol                       9.5       189500.0  ...   \n",
       "4            Manual    Petrol                       7.2        96127.0  ...   \n",
       "\n",
       "  has_heated_seats  has_leather_interior has_navigation  has_panoramic_roof  \\\n",
       "0            False                 False          False               False   \n",
       "1            False                 False          False               False   \n",
       "2            False                 False          False               False   \n",
       "3            False                 False          False               False   \n",
       "4            False                 False          False               False   \n",
       "\n",
       "   has_sport_features  has_trailer_hitch  has_tuev  is_cabrio  is_combi  \\\n",
       "0               False              False     False      False     False   \n",
       "1               False              False     False      False     False   \n",
       "2               False              False     False      False     False   \n",
       "3               False              False     False      False     False   \n",
       "4               False              False     False      False     False   \n",
       "\n",
       "   is_coupe  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "df = preprocessing_pipeline_offerdesc(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d211193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor Imputation:\n",
      "fuel_consumption:\n",
      "12967 in X_train\n",
      "3233 in X_test\n",
      "power_ps:\n",
      "61 in X_train\n",
      "11 in X_test\n",
      "------------------------------\n",
      "Fehlende Werte nach Imputation:\n",
      "fuel_consumption:\n",
      "88 in X_train\n",
      "26 in X_test\n",
      "power_ps:\n",
      "1 in X_train\n",
      "0 in X_test\n",
      "------------------------------\n",
      "✅ RFE ausgewählt: 28 Features\n",
      "\n",
      "🟢 Behaltene Features:\n",
      "['num__year' 'num__power_ps' 'num__fuel_consumption_l_100km'\n",
      " 'num__mileage_in_km' 'num__has_acc' 'num__has_additional_motortechnology'\n",
      " 'num__has_all_wheel_drive' 'num__has_assistence_systems'\n",
      " 'num__has_dab_radio' 'num__has_diesel_particel_feature'\n",
      " 'num__has_doubleclutch_transmission' 'num__has_heated_seats'\n",
      " 'num__has_leather_interior' 'num__has_navigation'\n",
      " 'num__has_panoramic_roof' 'num__has_sport_features'\n",
      " 'num__has_trailer_hitch' 'num__has_tuev' 'num__is_cabrio' 'num__is_combi'\n",
      " 'num__is_coupe' 'cat__brand' 'cat__model' 'cat__color'\n",
      " 'cat__transmission_type' 'cat__fuel_type' 'cat__offer_description'\n",
      " 'cat__offer_description_cleaned']\n",
      "\n",
      "🔴 Entfernte Features:\n",
      "[]\n",
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 0.1, 'model__n_neighbors': 100}\n",
      "\n",
      "Test MSE: 731834067.13\n",
      "Test RMSE: 27052.43\n",
      "Test MAE: 15871.35\n",
      "Test R²: 0.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 4.3 - Local Ridge Regression: Version 3.2 + Offer Description + RFE (Label Encoding)\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch():\n",
    "   # Preprocessing\n",
    "    df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "    df = preprocessing_pipeline_offerdesc(df)\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    print(\"Fehlende Werte vor Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "    \n",
    "    # Mapping aus dem Trainingsset lernen\n",
    "    fuel_maps = get_imputation_maps(X_train, target_col='fuel_consumption_l_100km')\n",
    "    ps_maps = get_imputation_maps(X_train, target_col='power_ps')\n",
    "\n",
    "    \n",
    "    # Mapping auf Trainings- und Testdaten anwenden\n",
    "    X_train = apply_imputation(X_train, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='fuel_consumption_l_100km', maps=fuel_maps)\n",
    "    X_train = apply_imputation(X_train, target_col='power_ps', maps=ps_maps)\n",
    "    X_test = apply_imputation(X_test, target_col='power_ps', maps=ps_maps)\n",
    "\n",
    "\n",
    "    print(\"Fehlende Werte nach Imputation:\")\n",
    "    print('fuel_consumption:')\n",
    "    print(X_train['fuel_consumption_l_100km'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['fuel_consumption_l_100km'].isna().sum(), \"in X_test\")\n",
    "    print('power_ps:')\n",
    "    print(X_train['power_ps'].isna().sum(), \"in X_train\")\n",
    "    print(X_test['power_ps'].isna().sum(), \"in X_test\")\n",
    "    print('-'*30)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('label_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # RFE vorbereiten\n",
    "    X_train_df = X_train.copy()\n",
    "    X_train_df['target'] = y_train\n",
    "    df = run_rfe_on_preprocessed(X_train_df, 'target', preprocessor)\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100],\n",
    "        'model__alpha': [0.1]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Bewertung\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nTest MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b29afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fehlende Werte vor Imputation:\n",
      "fuel_consumption:\n",
      "12967 in X_train\n",
      "3233 in X_test\n",
      "power_ps:\n",
      "61 in X_train\n",
      "11 in X_test\n",
      "------------------------------\n",
      "Fehlende Werte nach Imputation:\n",
      "fuel_consumption:\n",
      "88 in X_train\n",
      "26 in X_test\n",
      "power_ps:\n",
      "1 in X_train\n",
      "0 in X_test\n",
      "------------------------------\n",
      "Starte Grid Search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "\n",
      " Bestes n_neighbors und alpha: {'model__alpha': 0.1, 'model__n_neighbors': 100}\n",
      "\n",
      " Bestes Modell (beste Pipeline):\n",
      "Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='median')),\n",
      "                                                                  ('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['year', 'power_ps',\n",
      "                                                   'fuel_consumption_l_100km',\n",
      "                                                   'mileage_in_km']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('ordinal',\n",
      "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
      "                                                                                  unknown_value=-1))]),\n",
      "                                                  ['brand', 'model', 'color',\n",
      "                                                   'transmission_type',\n",
      "                                                   'fuel_type', 'segment'])])),\n",
      "                ('model', LocalRidgeRegressor(alpha=0.1, n_neighbors=100))])\n",
      "\n",
      " Beste Hyperparameter:\n",
      "{'model__alpha': 0.1, 'model__n_neighbors': 100}\n",
      "\n",
      " Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\n",
      "-15475.669422323415\n",
      "Test MSE: 122309576.88\n",
      "Test RMSE: 11059.37\n",
      "Test MAE: 3707.75\n",
      "Test R²: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 4.4 - Local Ridge Regression: Version 3.2 + Segments\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Hauptfunktion\n",
    "def main_local_ridge_regression_with_gridsearch_2():\n",
    "    # Preprocessing\n",
    "    df = preprocessing_pipeline_impute(path = 'data.csv')\n",
    "    df = preprocessing_pipeline_segment(df)\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline\n",
    "    model = LocalRidgeRegressor()\n",
    "\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # Gridsearch\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100],\n",
    "        'model__alpha': [0.1]  # Ridge Regularisierung (klein/mittel/stark)\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        full_pipeline,\n",
    "        param_grid,\n",
    "        cv=3,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    print(\"Starte Grid Search...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\n Bestes n_neighbors und alpha:\", grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Modell (beste Pipeline):\")\n",
    "    print(grid_search.best_estimator_)\n",
    "\n",
    "    print(\"\\n Beste Hyperparameter:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    print(\"\\n Bestes Cross-Validation Ergebnis (neg_root_mean_squared_error):\")\n",
    "    print(grid_search.best_score_)\n",
    "\n",
    "    # Bewertung\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Test MSE: {mse:.2f}\")\n",
    "    print(f\"Test RMSE: {rmse:.2f}\")\n",
    "    print(f\"Test MAE: {mae:.2f}\")\n",
    "    print(f\"Test R²: {r2:.2f}\")\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch_2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1df930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Segmentweise Modellbewertung:\n",
      "              segment           MSE           RMSE           MAE        R2\n",
      "0                 Van  6.069469e+07    7790.679959   3795.135486  0.780824\n",
      "1       Kompaktklasse  4.745657e+07    6888.872806   2125.211073  0.656281\n",
      "2                 SUV  8.347351e+07    9136.383769   4033.842748  0.895114\n",
      "3          Kleinwagen  9.152619e+06    3025.329623   1666.242241  0.844893\n",
      "4          Sportwagen  4.517932e+08   21255.428223  10648.432927  0.886246\n",
      "5        Mittelklasse  2.931806e+07    5414.615795   2907.484854  0.852424\n",
      "6  Obere Mittelklasse  8.816683e+07    9389.719335   4524.039191  0.767138\n",
      "7         Luxusklasse  4.380596e+08   20929.872529  13233.819486  0.904198\n",
      "8     Supersportwagen  1.091026e+10  104452.192198  75953.586472  0.754539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bibbe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Version 4.4.1 - Evaluierung nach Segmenten\n",
    "\n",
    "class LocalRidgeRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, n_neighbors=10, alpha=1.0):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.alpha = alpha\n",
    "        self.nn = None\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = pd.DataFrame(X)\n",
    "        self.y_train = pd.Series(y)\n",
    "        self.nn = NearestNeighbors(n_neighbors=self.n_neighbors)\n",
    "        self.nn.fit(self.X_train)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        predictions = []\n",
    "        for x in X.values:\n",
    "            distances, indices = self.nn.kneighbors([x])\n",
    "            X_neighbors = self.X_train.iloc[indices[0]]\n",
    "            y_neighbors = self.y_train.iloc[indices[0]]\n",
    "            model = Ridge(alpha=self.alpha)\n",
    "            model.fit(X_neighbors, y_neighbors)\n",
    "            pred = model.predict([x])\n",
    "            predictions.append(pred[0])\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Funktion zur Bewertung des Modells nach einzelnen Segmenten\n",
    "def evaluate_by_segment(X_test, y_test, y_pred, segments):\n",
    "    segment_results = []\n",
    "    for segment in segments.unique():\n",
    "        mask = segments == segment\n",
    "        mse = mean_squared_error(y_test[mask], y_pred[mask])\n",
    "        rmse = mse ** 0.5\n",
    "        mae = mean_absolute_error(y_test[mask], y_pred[mask])\n",
    "        r2 = r2_score(y_test[mask], y_pred[mask])\n",
    "        segment_results.append({\n",
    "            'segment': segment,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2': r2\n",
    "        })\n",
    "    return pd.DataFrame(segment_results)\n",
    "\n",
    "def main_local_ridge_regression_with_gridsearch_segments():\n",
    "    df = preprocessing_pipeline_impute(path='data.csv')\n",
    "    df = preprocessing_pipeline_segment(df)\n",
    "    X_train, X_test, y_train, y_test, X, y, categorical_features, numeric_features = split_data(df)\n",
    "\n",
    "    # Transformer\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    # Pipeline und GridSearch\n",
    "    model = LocalRidgeRegressor()\n",
    "    full_pipeline = Pipeline([\n",
    "        ('imp_fc', ContextImputer('fuel_consumption_l_100km')),\n",
    "        ('imp_ps', ContextImputer('power_ps')),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    param_grid = {\n",
    "        'model__n_neighbors': [100],\n",
    "        'model__alpha': [0.1]\n",
    "    }\n",
    "    grid_search = GridSearchCV(full_pipeline, param_grid, cv=3,\n",
    "                               scoring='neg_root_mean_squared_error',\n",
    "                               n_jobs=-1, verbose=2)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Segmentbewertung\n",
    "    segment_results = evaluate_by_segment(X_test, y_test, y_pred, X_test['segment'])\n",
    "\n",
    "    print(\"Segmentweise Modellbewertung:\")\n",
    "    print(segment_results)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "# Aufruf der Funktion\n",
    "best_model = main_local_ridge_regression_with_gridsearch_segments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff377be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 4.5. - Local Ridge Regression: Best Combo from Versions 3 + Offer Description + Segments\n",
    "\n",
    "# Macht tatsächlich irgendwie keinen Sinn, weil Offer_Description die Vorhersagen so schlecht macht"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Data Mining Project Kernel",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
